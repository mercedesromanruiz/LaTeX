\chapter{Introducción}
\section{Espacios Vectoriales}
\begin{definition}
    Un espacio vectorial sobre el campo num\'erico $K$ ($K = \mathbb{R}$ o $K = \mathbb{C}$) es un conjunto no vacío $V$, cuyos elementos se llaman vectores y en el cual se definen dos operaciones, denominadas suma y multiplicaci\'on por escalares, que cumplen las siguientes propiedades:
    \begin{enumerate}
        \item la suma es conmutativa y asociativa;
        \item existe un elemento $0 \in V$ (el vector cero o vector nulo) tal que $v + 0 = v$ para cada $v \in V$;
        \item $0 \cdot v = 0$, $1 \cdot v = v$, para cada $v \in V$, donde 0 y 1 son respectivamente el cero y la unidad de $K$;
        \item para cada elemento $v \in V$ existe su opuesto, $-v$, en $V$ tal que $v + (-v) = 0$;
        \item se cumplen las siguientes propiedades distributivas:
        \[\forall \alpha \in K, \forall v,w \in V, \alpha(v + w) = \alpha v + \alpha w\]
        \[\forall \alpha , \beta \in K, \forall v \in V, (\alpha + \beta)v = \alpha v + \beta v\]
        \item se cumple la siguiente propiedad asociativa:
        \[\forall \alpha , \beta \in K, \forall v \in V, (\alpha \beta)v = \alpha (\beta v)\]
    \end{enumerate}
\end{definition}

\begin{definition}
    Decimos que una parte no vac\'ia $W$ de $V$ es un subespacio vectorial de $V$ si $W$ es un espacio vectorial sobre $K$.
\end{definition}

\begin{definition}
    Un sistema de vectores ${v_1, ..., v_n}$ de un espacio vectorial $V$ se llama linealmente independiente si la relaci\'on
    \[\alpha_1 v_1 + \alpha_2 v_2 +...+ \alpha_m v_m = 0\]
    con $\alpha_1, \alpha_2, ..., \alpha_m \in K$ implica que $\alpha_1 = \alpha_2 = ...= \alpha_m = 0$. En caso contrario, el sistema se llamar\'a linealmente dependiente.
\end{definition}

Llamamos base de $V$ a cualquier sistema generador linealmente independiente de $V$. Si ${u_1, ..., u_n}$ es una base de $V$, la expresi\'on $v = v_1 u_1 + ... + v_n u_n$ se llama la descomposici\'on de $v$ con respecto a la base y los escalares $v_1, ..., v_n \in K$ son los componentes de $v$ con respecto a la base dada. Adem\'as, se cumple la siguiente propiedad.

\begin{property}
    Sea $V$ un espacio vectorial que admite una base de $n$ vectores. Entonces, todo sistema de vectores linealmente independientes de $V$ tiene como m\'aximo $n$ elementos y cualquier otra base de $V$ tiene $n$ elementos. El n\'umero $n$ se llama la dimensi\'on de $V$ y escribimos $\dim(V) = n$.
    Si, en cambio, para cualquier $n$ siempre existen $n$ vectores linealmente independientes en $V$, el espacio vectorial se llama de dimensi\'on infinita.
\end{property}

\section{Matrices}
Sean $m$ y $n$ dos enteros positivos. Llamamos matriz de $m$ filas y $n$ columnas, o una matriz $m \times n$, o una matriz $(m, n)$, con elementos en $K$, a un conjunto de $mn$ escalares $a_{ij} \in K$, con $i = 1,...,m$ y $j = 1,...,n$, representada en el siguiente arreglo rectangular
\begin{equation}
    A = \begin{bmatrix}
        a_{11} & a_{12} & \cdots & a_{1n} \\
        a_{21} & a_{22} & \cdots & a_{2n} \\
        \vdots & \vdots & \ddots & \vdots \\
        a_{m1} & a_{m2} & \cdots & a_{mn}
        \end{bmatrix}
    \label{matrices}
\end{equation}
Cuando $K = \mathbb{R}$ o $K = \mathbb{C}$, escribiremos respectivamente $A \in \mathbb{R}^{m \times n}$ o $A \in \mathbb{C}^{m \times n}$, para detallar explícitamente los campos numéricos a los que pertenecen los elementos de $A$. Usaremos letras mayúsculas para denotar las matrices, mientras que las letras minúsculas correspondientes a esas letras mayúsculas denotarán las entradas de la matriz.

Abreviaremos (\ref{matrices}) como $A = (a_{ij})$ con $i = 1,...,m$ y $j = 1,...,n$. El índice $i$ se llama índice de fila, mientras que $j$ es el índice de columna. El conjunto $(a_{i1}, a_{i2}, ..., a_{in})$ se llama la i-ésima fila de $A$; igualmente, $(a_{1j}, a_{2j}, ..., a_{mj})$ es la j-ésima columna de $A$.

Si $n = m$, la matriz se llama cuadrada o de orden $n$, y el conjunto de las entradas $(a_{11}, a_{22}, ..., a_{nn})$ se llama su diagonal principal.

Una matriz que tenga una fila o una columna se llama vector fila o vector columna, respectivamente. A menos que se especifique lo contrario, siempre asumiremos que un vector es un vector columna. En el caso $n = m = 1$, la matriz simplemente denotará un escalar de $K$.

\begin{definition}
    Sea $A$ una matriz $m \times n$. Sean $1 \leq i_1 < i_2 < ... < i_k \leq m$ y $1 \leq j_1 < j_2 < ... < j_l \leq n$ dos conjuntos de índices contiguos. La matriz $S(k \times l)$ de entradas $s_{pq} = a_{i_p j_q}$ con $p = 1, ..., k$, $q = 1, ..., l$ se llama submatriz de $A$. Si $k = l$ y $i_r = j_r$ para $r = 1, ..., k$, $S$ se llama submatriz principal de $A$.
\end{definition}

\begin{definition}
    Una matriz $A(m \times n)$ se llama particionada en bloques o se dice que está particionada en submatrices si
    \[
    A = \begin{bmatrix}
        A_{11} & A_{12} & \cdots & A_{1l} \\
        A_{21} & A_{22} & \cdots & A_{2l} \\
        \vdots & \vdots & \ddots & \vdots \\
        A_{k1} & A_{k2} & \cdots & A_{kl}
    \end{bmatrix}
    \]
    donde $A_{ij}$ son submatrices de $A$.
\end{definition}


\section{Operaciones con matrices}
\subsection{Matrices y transformaciones lineales}
\begin{definition}
    Una transformación lineal para $\mathbb{C}^n$ en $\mathbb{C}^m$ es una función $f: \mathbb{C}^n \rightarrow \mathbb{C}^m$ tal que $f(\alpha x + \beta y) = \alpha f(x) + \beta f(y)$, $\forall \alpha , \beta \in K$ y $\forall x, y \in \mathbb{C}^n$.
\end{definition}

El siguiente resultado vincula matrices y transformaciones lineales.

\begin{property}
    Sea $f: \mathbb{C}^n \rightarrow \mathbb{C}^m$ una transformación lineal. Entonces, existe una matriz única $A_f \in \mathbb{C}^{m \times n}$ tal que
    \begin{equation}
        f(x) = A_f x \quad \forall x \in \mathbb{C}^n
        \label{Matrices and Linear Mappings}
    \end{equation}
    Inversamente, si $A_f \in \mathbb{C}^{m \times n}$, entonces la función definida en (\ref{Matrices and Linear Mappings}) es una transformación lineal de $\mathbb{C}^n$ en $\mathbb{C}^m$.
\end{property}

\section{Bien planteamiento y número de condición de un problema}
Consideremos el siguiente problema: encontrar $x$ tal que
\begin{equation}
    F(x, d) = 0
    \label{problem}
\end{equation}
donde $d$ es el conjunto de datos del cual depende la solución y $F$ es la relación funcional entre $x$ y $d$. Según el tipo de problema representado en (\ref{problem}), las variables $x$ y $d$ pueden ser números reales, vectores o funciones. Típicamente, (\ref{problem}) se llama un problema directo si $F$ y $d$ están dados y $x$ es desconocido, un problema inverso si $F$ y $x$ son conocidos y $d$ es el desconocido, y un problema de identificación cuando $x$ y $d$ están dados mientras que la relación funcional $F$ es desconocida.

El problema (\ref{problem}) está bien planteado si admite una solución única $x$ que depende continuamente de los datos. Usaremos los términos bien planteado y estable de manera intercambiable y a partir de ahora solo trataremos problemas bien planteados.

Un problema que no goza de la propiedad anterior se llama mal planteado o inestable y antes de abordar su solución numérica debe ser regularizado, es decir, debe transformarse adecuadamente en un problema bien planteado. De hecho, no es adecuado pretender que el método numérico pueda curar las patologías de un problema intrínsecamente mal planteado.

Sea $D$ el conjunto de datos admisibles, es decir, el conjunto de los valores de $d$ en correspondencia con los cuales el problema (\ref{problem}) admite una solución única. La dependencia continua de los datos significa que pequeñas perturbaciones en los datos $d$ de $D$ producen "pequeños" cambios en la solución $x$. Precisamente, sea $d \in D$ y denotemos por $\delta d$ una perturbación admisible en el sentido de que $d + \delta d \in D$ y por $\delta x$ el cambio correspondiente en la solución, de manera que
\begin{equation}
    F(x + \delta x, d + \delta d) = 0
    \label{equation 2.2}
\end{equation}
Entonces, requerimos que
\begin{multline}
    \exists \eta_0 =\eta_0(d) > 0, \quad \exists K_0 = K_0 (d) \text{ tal que si } \\
     \| \delta d \| \leq \eta_0 \text{ entonces } \| \delta x \| \leq K_0 \| \delta d \|
     \label{equation(2.3)}
\end{multline}

Las normas usadas para los datos y para la solución pueden no coincidir, siempre que $d$ y $x$ representen variables de diferentes tipos.

\begin{remark}
    La propiedad de dependencia continua de los datos podría haberse expresado de la siguiente manera alternativa, que es más parecida a la forma clásica del Análisis $\forall \epsilon > 0\ \exists \delta = \delta (\epsilon)$ tal que si $\| \delta d \| \leq \delta$ entonces $\| \delta x \| \leq \epsilon$.
    
    La forma (\ref{equation(2.3)}) es, sin embargo, más adecuada para expresar en lo siguiente el concepto de estabilidad numérica, es decir, la propiedad de que pequeñas perturbaciones en los datos producen perturbaciones del mismo orden en la solución.
\end{remark}

Con el objetivo de hacer que el análisis de estabilidad sea más cuantitativo, introducimos la siguiente definición.

\begin{definition}
    Para el problema (\ref{problem}) definimos el número de condición relativo como
    \begin{equation}
        K(d) = \sup\{ \frac{\| \delta x \| / \| x \|}{\| \delta d \| / \|d \|}, \delta d \neq 0, d + \delta d \in D \}
        \label{equation 2.4}
    \end{equation}
    Siempre que $d = 0$ o $x = 0$, es necesario introducir el número de condición absoluto, dado por
    \begin{equation}
        K_{abs}(d) = \sup \{ \frac{ \| \delta x \|}{ \| \delta d \|}, \delta d \neq 0, d + \delta d \in D \}
        \label{equation 2.5}
    \end{equation}
\end{definition}

El problema (\ref{problem}) se llama mal condicionado si  $K(d)$ es "grande" para cualquier dato admisible $d$.

La propiedad de que un problema esté bien condicionado es independiente del método numérico que se use para resolverlo. De hecho, es posible generar esquemas numéricos estables e inestables para resolver problemas bien condicionados. El concepto de estabilidad para un algoritmo o para un método numérico es análogo al utilizado para el problema (\ref{problem}) y se hará preciso en la siguiente sección.

\begin{remark}
    (Problemas mal planteados) Incluso en el caso en que el número de condición no exista (formalmente, sea infinito), no necesariamente es cierto que el problema esté mal planteado. De hecho, existen problemas bien planteados para los cuales el número de condición es infinito, pero que pueden ser reformulados en problemas equivalentes con un número de condición finito.
\end{remark}

Si el problema (\ref{problem}) admite una solución única, entonces necesariamente existe una aplicación $G$, que llamamos resolvente, entre los conjuntos de los datos y las soluciones, tal que
\begin{equation}
    x = G(d) \text{, es decir } F(G(d), d) = 0
    \label{equation 2.6}
\end{equation}
Según esta definición, (\ref{equation 2.2}) da lugar a $x + \delta x = G(d + \delta d)$. Suponiendo que $G$ sea diferenciable en $d$ y denotando formalmente por $G'(d)$ su derivada con respecto a $d$ (si $G: \mathbb{R}^n \rightarrow \mathbb{R}^m$, $G'(d)$ será la matriz jacobiana de $G$ evaluada en el vector $d$), una expansión de Taylor de $G$ truncada en primer orden asegura que 
\[G(d + \delta d) - G(d) = G'(d) \delta d + o(\| \delta d \|) \quad \text{para } \delta d \rightarrow 0 \]
donde $\| \cdot \|$ es una norma vectorial adecuada y $o(\cdot)$ es el símbolo clásico de infinitesimal que denota un término infinitesimal de orden superior con respecto a su argumento. Despreciando el infinitesimal de orden superior con respecto a $\| \delta d \|$, de (\ref{equation 2.4}) y (\ref{equation 2.5}) deducimos respectivamente que
\begin{equation}
    K(d) \approx \| G'(d) \| \frac{\| d \|}{\| G(d) \|}, \quad K_{abs}(d) \approx \| G'(d) \|
    \label{equation 2.7}
\end{equation}
donde el símbolo $\| \cdot \|$, cuando se aplica a una matriz, denota la norma de matriz inducida (\ref{equation 1.19}) asociada con la norma vectorial introducida anteriormente. Las estimaciones en (\ref{equation 2.7}) son de gran utilidad para realizar análisis cualitativos sobre la condición de un problema.

\subsection{Relaciones entre Estabilidad y Convergencia}
Los conceptos de estabilidad y convergencia están fuertemente conectados.

En primer lugar, si el problema (\ref{problem}) está bien planteado, una condición necesaria para que el problema numérico (\ref{equation 2.12}) sea convergente es que sea estable.

Supongamos entonces que el método es convergente, es decir, que (\ref{equation 2.20}) se cumple para un $\epsilon > 0$. Tenemos
\begin{multline}
    \| \delta x_n \| = \| x_n(d + \delta d_n) - x_n(d) \| \leq \| x_n(d) - x(d) \| \\
    + \| x(d) - x(d + \delta d_n) \| + \| x(d + \delta d_n) - x_n (d + \delta d_n) \| \\
    \leq K(\delta (n_0, \epsilon), d) \| \delta d_n \| + \epsilon
    \label{equation 2.24}
\end{multline}
habiendo utilizado (\ref{equation(2.3)}) y (\ref{equation 2.21}) dos veces. Ahora, eligiendo $\delta d_n$ tal que $\| \delta d_n \| \leq \eta_0$, deducimos que $\| \delta d_n \| \leq \eta_0$, lo que nos lleva a que $\| \delta x_n \| / \| \delta d_n \|$ puede ser acotado por $K_0 = K(\delta (n_0 , \epsilon), d) + 1$, siempre que $\epsilon \leq \| \delta d_n \|$, de modo que el método es estable. Así, nos interesan los métodos numéricos estables, ya que solo estos pueden ser convergentes.

La estabilidad de un método numérico se convierte en una condición suficiente para que el problema numérico (\ref{equation 2.12}) converja si este último también es consistente con el problema (\ref{problem}). De hecho, bajo estas suposiciones, tenemos
\[
\|x(d + \delta d_n) - x_n(d + \delta d_n)\| \leq \| x(d + \delta d_n) - x(d) \|
\]
\[
+ \| x(d) - x_n(d) \| + \| x_n(d) - x_n(d + \delta d_n)\|
\]

Gracias a (\ref{equation(2.3)}), el primer término en el lado derecho puede ser acotado por $\| \delta d_n \|$. Un límite similar se aplica al tercer término, debido a la propiedad de estabilidad (\ref{equation 2.16}). Finalmente, respecto al término restante, si $F_n$ es diferenciable con respecto a la variable $x$, una expansión en serie de Taylor da
\[
F_n(x(d), d) - F_n(x_n(d), d) = \frac{\partial F_n}{\partial x}|_{(x, d)}(x(d) - x_n(d))
\]
para un adecuado $x$ "entre" $x(d)$ y $x_n(d)$. Suponiendo además que $\partial f_n / \partial x$ es invertible, obtenemos
\begin{equation}
    x(d) - x_n(d) = \left( \frac{\partial F_n}{\partial x} \right)^{-1}_{|(x, d)} [F_n(x(d), d) - F_n(x_n(d), d)]
    \label{equation 2.25}
\end{equation}

Por otro lado, al reemplazar $F_n(x_n(d), d)$ por $F_n(x(d), d)$ y pasar a las normas, encontramos
\[
\| x(d) - x_n(d) \| \leq \| \left( \frac{\partial F_n}{\partial x} \right)^{-1}_{|(x,d)} \| \| F_n(x(d),d) - F(x(d), d)\|
\]

Gracias a (\ref{equation 2.13}) podemos concluir que $\|x(d) - x_n(d)\| \rightarrow 0$ cuando $n \rightarrow \infty$. El resultado que acabamos de demostrar, aunque expresado en términos cualitativos, es un hito en el análisis numérico, conocido como el teorema de equivalencia (o teorema de Lax-Richtmyer): "para un método numérico consistente, la estabilidad es equivalente a la convergencia".

\section{Fuentes de Error en Modelos Computacionales}

Siempre que el problema numérico (\ref{equation 2.12}) sea una aproximación al problema matemático (\ref{problem}) y este último sea a su vez un modelo de un problema físico, diremos que (\ref{equation 2.12}) es un modelo computacional para el PP.

En este proceso, el error global, denotado por $e$, se expresa como la diferencia entre la solución realmente computada, $\hat{x}_n$, y la solución física, $x_{ph}$, de la cual $x$ proporciona un modelo. El error global $e$ del modelo matemático, dado por $x - x_{ph}$, y el error $e_c$ del modelo computacional, $\hat{x}_n - x$, es decir, $e = e_m + e_c$.

El error $e_m$ tendrá en cuenta el error del modelo matemático en sentido estricto y el error en los datos. De manera similar, $e_c$ resulta ser la combinación del error de discretización numérica $e_n = x_n - x$, el error $e_a$ introducido por el algoritmo numérico y el error de redondeo introducido por la computadora durante la solución del problema (\ref{equation 2.12}).

En general, podemos esbozar las siguientes fuentes de error:
\begin{enumerate}
    \item Error debido al modelo, que puede ser controlado mediante una adecuada elección del modelo matemático;
    \item Errores en los datos, que pueden reducirse mejorando la precisión en la medición de los propios datos;
    \item Error de truncamiento, que surge al haber reemplazado en el modelo numérico límites por operaciones que involucran un número finito de pasos;
    \item Errores de redondeo.
\end{enumerate}

El error de los ítems 3 y 4 da lugar al error computacional. Un método numérico será convergente si este error puede hacerse arbitrariamente pequeño al aumentar el esfuerzo computacional. Por supuesto, la convergencia es el objetivo principal, aunque no único, de un método numérico, siendo los otros la precisión, la fiabilidad y la eficiencia.

La precisión significa que los errores son pequeños respecto a una tolerancia fija. Usualmente, se cuantifica por el orden de infinitesimal del error $e_n$ con respecto al parámetro característico de discretización. Por cierto, cabe señalar que la precisión de la máquina no limita, en términos teóricos, la precisión.

La fiabilidad significa que es probable que el error global se garantice por debajo de una cierta tolerancia. Por supuesto, un modelo numérico solo puede considerarse confiable si ha sido adecuadamente probado, es decir, aplicado con éxito a varios casos de prueba.

La eficiencia significa que la complejidad computacional necesaria para controlar el error sea lo más pequeña posible.

Por algoritmo entendemos una directiva que indica, a través de operaciones elementales, todos los pasos necesarios para resolver un problema específico. Un algoritmo puede, a su vez, contener sub-algoritmos y debe tener la característica de terminar después de un número finito de operaciones elementales. Como consecuencia, el ejecutor del algoritmo debe encontrar dentro del algoritmo mismo todas las instrucciones para resolver completamente el problema planteado.

Finalmente, la complejidad de un algoritmo es una medida de su tiempo de ejecución. Calcular la complejidad de un algoritmo es, por lo tanto, parte del análisis de la eficiencia de un método numérico. Dado que se pueden emplear varios algoritmos con diferentes complejidades para resolver el mismo problema $P$, es útil introducir el concepto de complejidad de un problema, que significa la complejidad del algoritmo que tiene la mínima complejidad entre los que resuelven $P$. La complejidad de un problema se mide típicamente mediante un parámetro directamente asociado con $P$.

\section{Representación en Computadora de Números}
Cualquier operación en una máquina está afectada por errores de redondeo o redondeo. Esto se debe al hecho de que en una computadora solo se puede representar un subconjunto finito del conjunto de números reales.

\subsection{El Sistema Posicional}
Sea una base $\beta \in \mathbb{N}$ fijada con $\beta \geq 2$, y sea $x$ un número real con un número finito de dígitos $x_k$ con $0 \leq x_k < \beta$ para $k = -m,...,n$. La notación (convencionalmente adoptada)
\begin{equation}
    x_\beta = (-1)^s [x_n x_{n-1}...x_1x_0x_{-1}x_{-2}...x_{-m}, x_n \neq 0]
    \label{equation 2.26}
\end{equation}
se llama la representación posicional de $x$ con respecto a la base $\beta$. El punto entre $x_0$ y $x_{-1}$ se llama punto decimal si la base es 10, punto binario si la base es 2, mientras que $s$ depende del signo de $x$ ($s=0$ si $x$ es positivo, $1$ si es negativo). La relación (\ref{equation 2.26}) significa en realidad
\[ x_\beta = (-1)^s \left( \sum_{k=-m}^{n} x_k \beta^k \right)\]

Cualquier número real puede ser aproximado por números que tengan una representación finita. De hecho, al haber fijado la base $\beta$, se cumple la siguiente propiedad
\[ \forall \epsilon > 0, \forall x_\beta \in \mathbb{R}, \exists y_\beta \in \mathbb{R} \text{ tal que } |y_\beta - x_\beta| < \epsilon\]
donde $y_\beta$ tiene una representación posicional finita.

De hecho, dado el número positivo $x_\beta = x_n x_{n-1}...x_1x_0x_{-1}x_{-2}...x_{-m}...$ con el número de dígitos, finitos o infinitos, para cualquier $r \geq 1$ se pueden construir dos números
\[x_\beta^{(l)} = \sum_{k = 0}^{r-1} x_{x-k} \beta^{n-k}, x_\beta^{(u)} = x_\beta^{(l)} = \beta^{n-r+1}\]
que tienen $r$ dígitos, tales que $x_\beta^{(l)} < x_\beta < x_\beta^{(u)}$ y $x_\beta^{(u)} - x_\beta^{(l)} = \beta^{n-r+1}$. Si se elige $r$ de manera que $\beta^{n-r+1} < \epsilon$, entonces tomando $y_\beta$ igual a $x_\beta^{(l)}$ o $x_\beta^{(u)}$ se obtiene la desigualdad deseada. Este resultado legitima la representación computacional de los números reales (y por lo tanto de un número finito de dígitos).

Aunque teóricamente hablando todas las bases son equivalentes, en la práctica computacional se emplean generalmente tres bases: la base 2 en binario, la base 10 o decimal y la base 16 o hexadecimal. En lo que sigue, supondremos que $\beta$ es un número entero par.

Para simplificar las notaciones, escribiremos $x$ en lugar de $x_\beta$, dejando la base $\beta$ entendida.


\section*{Ejercicios}
\noindent (1) Se considera la siguiente sucesión definida por recursión
\[x_0 = 1 \quad x_1 = \frac{1}{5} \quad x_{n+1} = \frac{36}{5} x_n - \frac{7}{5} x_{n-1}\]
Esta sucesión tiene como solución $x_n = \frac{1}{5^n}$. Utilizar Matlab para calcular $\frac{1}{5^n}$ utilizando la sucesión recusiva del principio, para $n \leq 32$. Hacer el estudio del error absoluto y  relativo.

\noindent (2) Repetir el ejercicio anterior tomando $x_0 = 2$ y $x_1 = \frac{36}{5}$, teniendo en cuenta que la solución es ahora $x_n = \frac{1}{5^n} + 7^n$.

\noindent (3) Compara los resultados de los ejercicios 1 y 2 y dar una explicación formal de lo que está sucediendo.